{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.utils.data.Dataset\n",
    "# 可自定义数据集\n",
    "# custom_dataset = CustomDataset() \n",
    "# CustomDataset(torch.utils.data.Dataset), 需定义好__init__(self), __getitem__(self, index)和__len__(self)\n",
    "\n",
    "# torch.utils.data.TensorDataset(data_tensor, target_tensor) # 包装数据和目标张量的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算数据集的均值和标准差\n",
    "# 输入PyTorch的dataset, 输出均值和标准差\n",
    "import numpy as np\n",
    "def compute_mean_and_std(dataset):\n",
    "    mean_r = 0\n",
    "    mean_g = 0\n",
    "    mean_b = 0\n",
    "    for img, _ in dataset:\n",
    "        img = np.asarray(img) # change PIL Image to numpy array\n",
    "        mean_b += np.mean(img[:, :, 0])\n",
    "        mean_g += np.mean(img[:, :, 1])\n",
    "        mean_r += np.mean(img[:, :, 2])\n",
    "\n",
    "    mean_b /= len(dataset)\n",
    "    mean_g /= len(dataset)\n",
    "    mean_r /= len(dataset)\n",
    "\n",
    "    diff_r = 0\n",
    "    diff_g = 0\n",
    "    diff_b = 0\n",
    "\n",
    "    N = 0\n",
    "\n",
    "    for img, _ in dataset:\n",
    "        img = np.asarray(img)\n",
    "\n",
    "        diff_b += np.sum(np.power(img[:, :, 0] - mean_b, 2))\n",
    "        diff_g += np.sum(np.power(img[:, :, 1] - mean_g, 2))\n",
    "        diff_r += np.sum(np.power(img[:, :, 2] - mean_r, 2))\n",
    "\n",
    "        N += np.prod(img[:, :, 0].shape)\n",
    "\n",
    "    std_b = np.sqrt(diff_b / N)\n",
    "    std_g = np.sqrt(diff_g / N)\n",
    "    std_r = np.sqrt(diff_r / N)\n",
    "\n",
    "    mean = (mean_b.item() / 255.0, mean_g.item() / 255.0, mean_r.item() / 255.0)\n",
    "    std = (std_b.item() / 255.0, std_g.item() / 255.0, std_r.item() / 255.0)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = None\n",
    "train_set = data.Subset(train_set, train_idx_normal=[])\n",
    "# 函数参数(dataset, indices): 获取指定一个索引序列对应的子数据集   \n",
    "# 返回一个'Subset'对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = None\n",
    "train_loader = data.DataLoader(dataset, 4) # 以简单的方式提供队列和线程\n",
    "# 第一个参数类型为torch.utils.data.Dataset, 第二个参数为batch_size\n",
    "# 还有参数num_workers, shuffle(训练集置为True), pin_memory, drop_last\n",
    "\t# 以及batch_sampler, collate_fn, sampler(当该参数为空时, 一般pin_memory=False)\n",
    "# pin_memory \n",
    "\t# torch.utils.data.DataLoader中尽量设置pin_memory=True\n",
    "\t# 对特别小的数据集如MNIST设置pin_memory=False反而更快一些\n",
    "# num_workers\n",
    "\t# 设置需要在实验中找到最快的取值\n",
    "\t# num_workers的经验设置值是自己电脑/服务器的CPU核心数, 如果CPU很强, RAM也很充足, 就可以设置得更大些\n",
    "# drop_last\n",
    "\t# 如果数据集大小不能被batch size整除, 则设置为True后可删除最后一个不完整的batch\n",
    "\t# 如果设为False并且数据集的大小不能被batch size整除, 则最后一个batch将更小\n",
    "\t# 训练使用的数据集, 开启drop_last, 这样如果最后一个batch小于你的batch_size, 会扔掉, 训练会更稳定\n",
    "# batch_sampler\n",
    "\t# 可来自BucketBatchSampler\n",
    "len(train_loader.dataset)  # 数据点的个数\n",
    "data_iter = iter(train_loader) # 当迭代开始时, 队列和线程开始从文件下载数据\n",
    "images, labels = data_iter.next() # Mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.utils.data.sampler.Sampler\n",
    "# 一个迭代器基类\n",
    "\t# def __init__(self, data_source):\n",
    "    #     pass\n",
    "\n",
    "    # def __iter__(self):\n",
    "    #     raise NotImplementedError\n",
    "\n",
    "    # def __len__(self):\n",
    "    #     raise NotImplementedError\n",
    "# SequentialSampler\n",
    "\t# 按顺序对数据集采样\n",
    "\t# 在__iter__方法中首先得到一个和data_source一样长度的range可迭代器; 每次只会返回一个索引值\n",
    "\t# 即iter(range(len(self.data_source)))\n",
    "# RandomSampler: \n",
    "\t# num_samples: 指定采样的数量, 默认是所有\n",
    "\t# replacement: 若为True, 则表示可以重复采样, 即同一个样本可以重复采样, 这样可能导致有的样本采样不到; 所以此时我们可以设置num_samples来增加采样数量使得每个样本都可能被采样到\n",
    "\t# __iter__方法\n",
    "\t\t# n = len(self.data_source)\n",
    "\t\t# if self.replacement:\n",
    "\t\t# \treturn iter(torch.randint(high=n, size=(self.num_samples,), dtype=torch.int64).tolist())\n",
    "\t\t# return iter(torch.randperm(n).tolist())\n",
    "# SubsetRandomSampler\n",
    "\t# 这个采样器常见的使用场景是将训练集划分成训练集和验证集 \n",
    "\t# init函数中给定indices\n",
    "\t# iter函数返回(self.indices[i] for i in torch.randperm(len(self.indices)))\n",
    "# WeightedRandomSampler\n",
    "\t# init函数中多了参数weights\n",
    "\t# self.weights = torch.tensor(weights, dtype=torch.double) 或 self.weights = torch.DoubleTensor(weights)\n",
    "\t# iter函数返回iter(torch.multinomial(self.weights, self.num_samples, self.replacement=True).tolist())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
