{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "'''\n",
    "1. 设置随机数种子\n",
    "2. 设备\n",
    "3. 其他参数设置\n",
    "4. 数据集\n",
    "5. 模型\n",
    "6. 定义损失函数和优化器\n",
    "7. 训练和测试\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机数种子\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed) # 为当前的GPU设置产生随机数的种子\n",
    "# torch.cuda.manual_seed_all(seed) # 为所有GPU设置产生随机数的种子\n",
    "torch.backends.cudnn.deterministic = True # 每次返回的卷积算法将是确定的; 会降低训练速度; 从checkpoints重新开始时会出现意外的结果\n",
    "# torch.backends.cudnn.benchmark = False # 设置为True, 可以大大提升卷积神经网络的运行速度; 可在网络训练开始前设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设备\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # 后续的数据以及模型需要.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 其他参数设置: 包括数据集, 模型, 训练等参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集\n",
    "\n",
    "torch.utils.data.DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型\n",
    "\n",
    "# 预训练模型\n",
    "from torch import nn\n",
    "# 若仅想在模型顶层微调, 则按如下设置:\n",
    "pretrain_model = None\n",
    "for param in pretrain_model.parameters():\n",
    "    param.requires_grad = False\n",
    "pretrain_model.fc = nn.Linear(pretrain_model.fc.in_features, 100) # 替换顶层来微调\n",
    "\n",
    "# 下载模型\n",
    "# 下载整个模型\n",
    "model = torch.load('model.ckpt', map_location=torch.device('cuda:0'))\n",
    "# map_location指明此时的device环境; map_location='cpu'\n",
    "# 如果保存的模型是torch.nn.DataParallel, 则当前的模型也需要是\n",
    "# model.load_state_dict(checkpoint['state_dict']) 只下载模型参数; model.load_state_dict(torch.load('params.ckpt'))\n",
    "\t# 函数load_state_dict有参数strict, 默认strict=True; 判断参数拷贝过程中是否有unexpected_keys或者missing_keys, 如果有就报错, 代码不能继续执行\n",
    "\t# 如果strict=False, 则会忽略这些细节\n",
    "\t# model.state_dict()返回的是一个OrderDict, 存储了网络结构的名字和对应的参数\n",
    "# optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "# 分布式模型\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "torch.nn.DataParallel(model, device_ids=[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "\n",
    "# 优化器\n",
    "optimizer = torch.optim.SGD() \n",
    "# 第一个参数可取model.parameters()\n",
    "# 还有参数lr, weight_decay, momentum\n",
    "torch.optim.Adam()\n",
    "# 第一个参数可取model.parameters()\n",
    "# 还有参数lr, weight_decay\n",
    "# Adagrad效果比Adam好的多\n",
    "\n",
    "# 可根据epoch修改学习率\n",
    "'''\n",
    "for param_group in optimizer.param_groups:  \n",
    "\tparam_group['lr'] = lr\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练和测试\n",
    "\n",
    "# 训练\n",
    "# 迭代进行(例如[for images, labels in train_loader]); 若只想显示最终的结果, 则可借助IPython的display.clear_output(wait=True), 置于输出语句之后\n",
    "'''\n",
    "1. 前向传播\n",
    "2. 计算损失loss\n",
    "3. 将梯度置零: optimizer.zero_grad()\n",
    "4. 反向传播: loss.backward()\n",
    "5. 更新参数: optimizer.step()\n",
    "'''\n",
    "\n",
    "# 可绘图(针对二维数据)\n",
    "# X是二维数据, y是标签\n",
    "from matplotlib import pyplot as plt\n",
    "def plot_data(X, y, auto=False, zoom=1):\n",
    "    X = X.cpu()\n",
    "    y = y.cpu()\n",
    "    plt.scatter(X.numpy()[:, 0], X.numpy()[:, 1], c=y, s=20, cmap=plt.cm.Spectral)\n",
    "    plt.axis('square')\n",
    "    plt.axis(np.array((-1.1, 1.1, -1.1, 1.1)) * zoom)\n",
    "    if auto is True: plt.axis('equal')\n",
    "    plt.axis('off')\n",
    "\n",
    "    _m, _c = 0, '.15'\n",
    "    plt.axvline(0, ymin=_m, color=_c, lw=1, zorder=0)\n",
    "    plt.axhline(0, xmin=_m, color=_c, lw=1, zorder=0)\n",
    "def plot_model(X, y, model):\n",
    "    model.cpu()\n",
    "    mesh = np.arange(-1.1, 1.1, 0.01)\n",
    "    xx, yy = np.meshgrid(mesh, mesh)\n",
    "    with torch.no_grad():\n",
    "        data = torch.from_numpy(np.vstack((xx.reshape(-1), yy.reshape(-1))).T).float()\n",
    "        Z = model(data).detach()\n",
    "    Z = np.argmax(Z, axis=1).reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.3)\n",
    "    plot_data(X, y)\n",
    "\n",
    "# 存储模型\n",
    "# 存储整个模型\n",
    "torch.save(model, 'model.ckpt') \n",
    "# 只保存模型参数\n",
    "torch.save(model.state_dict(), 'params.ckpt')\n",
    "# 可保存自定义字典, 文件名如ckpt.pth.tar\n",
    "\t# 一般包括模型, 优化器, 迭代轮次epoch(便于中断后恢复训练后), 最佳acc\n",
    "import shutil\n",
    "start_epoch = 0\n",
    "resume = 0\n",
    "num_epochs = None\n",
    "current_acc = None\n",
    "if resume: # resume为参数, 第一次训练时设为0, 中断再训练时设为1\n",
    "    model_path = os.path.join('model', 'best_checkpoint.pth.tar')\n",
    "    assert os.path.isfile(model_path)\n",
    "    checkpoint = torch.load(model_path)\n",
    "    best_acc = checkpoint['best_acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    print('Load checkpoint at epoch {}.'.format(start_epoch))\n",
    "    print('Best accuracy so far {}.'.format(best_acc))\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs): \n",
    "    ... \n",
    "\n",
    "    # Test the model\n",
    "    ...\n",
    "\n",
    "    # save checkpoint\n",
    "    is_best = current_acc > best_acc\n",
    "    best_acc = max(current_acc, best_acc)\n",
    "    checkpoint = {\n",
    "        'best_acc': best_acc,\n",
    "        'epoch': epoch + 1,\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }\n",
    "    model_path = os.path.join('model', 'checkpoint.pth.tar')\n",
    "    best_model_path = os.path.join('model', 'best_checkpoint.pth.tar')\n",
    "    torch.save(checkpoint, model_path)\n",
    "    if is_best:\n",
    "        shutil.copy(model_path, best_model_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
